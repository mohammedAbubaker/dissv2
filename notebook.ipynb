{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d10731c-728b-43e9-b79e-2fda704810ac",
   "metadata": {},
   "source": [
    "## Define imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8633e56-1a0f-456f-a94d-3b4b034b9abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as to\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "from plyfile import PlyData\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839b068e-fb3a-4540-b096-0bc87dca1e49",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a303b863-27e2-4a05-9437-c3259ac7a38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def broadcast(gauss_batch, ray_batch):\n",
    "    \n",
    "    # Split up gauss_batch\n",
    "    means, covariances, opacities, normals, reference_normals = gauss_batch\n",
    "    # Split up ray_batch\n",
    "    ray_oris, ray_dirs = ray_batch\n",
    "    \n",
    "    R = ray_oris.shape[0]\n",
    "    G = means.shape[0]\n",
    "\n",
    "    bcast_ray_oris = ray_oris.unsqueeze(1)\n",
    "    # (N_rays, 1, 3)\n",
    "    bcast_ray_dirs = ray_dirs.unsqueeze(1)\n",
    "    # (1, N_gaussians, 3)\n",
    "    bcast_means = means.unsqueeze(0)\n",
    "    # (1, N_gaussians, 3)\n",
    "    bcast_covariances = covariances.unsqueeze(0)\n",
    "    # (1, N_gaussians)\n",
    "    bcast_opacities = opacities.unsqueeze(0)\n",
    "    # (1, N_gaussians, 3)\n",
    "    bcast_normals = normals.unsqueeze(0)\n",
    "    # (1, N_gaussians, 3)\n",
    "    bcast_reference_normals = reference_normals.unsqueeze(0)\n",
    "\n",
    "    return (\n",
    "        bcast_means,\n",
    "        bcast_covariances,\n",
    "        bcast_opacities,\n",
    "        bcast_normals,\n",
    "        bcast_reference_normals,\n",
    "        bcast_ray_oris,\n",
    "        bcast_ray_dirs\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5336016-661b-4579-b2b6-dc9d96c6b16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sphere_rays(center, radius, n):\n",
    "    # Generate random angles for spherical coordinates\n",
    "    theta = to.rand(n, 1) * 2 * to.pi  # Azimuthal angle\n",
    "    phi = to.rand(n, 1) * to.pi        # Polar angle\n",
    "\n",
    "    # Spherical to Cartesian conversion\n",
    "    x = radius * to.sin(phi) * to.cos(theta)\n",
    "    y = radius * to.sin(phi) * to.sin(theta)\n",
    "    z = radius * to.cos(phi)\n",
    "\n",
    "    # Combine into ray origins\n",
    "    ray_oris = to.hstack((x, y, z))\n",
    "\n",
    "    # Ray directions pointing outward from the center\n",
    "    ray_dirs = ray_oris - center\n",
    "    # Normalise ray dirs\n",
    "    ray_dirs = ray_dirs / to.linalg.norm(ray_dirs)\n",
    "\n",
    "    return ray_oris, ray_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff616ecc-e501-4de2-9d04-73aa839467be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pairwise_great_circle(points, radius=1.0):\n",
    "    # Normalize points to lie on the unit sphere\n",
    "    points_normalized = points / points.norm(dim=1, keepdim=True)\n",
    "    # Compute the pairwise dot product; for unit vectors, this equals cos(theta)\n",
    "    dot_prod = to.mm(points_normalized, points_normalized.t())\n",
    "    # Clamp to ensure numerical stability\n",
    "    dot_prod = to.clamp(dot_prod, -1.0, 1.0)\n",
    "    # Compute the great circle distance (angle in radians)\n",
    "    distances = to.acos(dot_prod)\n",
    "    # Scale by the sphere's radius if needed\n",
    "    return distances * radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9430a01c-3cc6-4696-9474-0e56016f3160",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_graph_laplacian(points, sigma, radius=1.0):\n",
    "    # Compute pairwise great circle distances\n",
    "    distances = compute_pairwise_great_circle(points, radius)\n",
    "    # Create weight matrix using a Gaussian kernel\n",
    "    W = to.exp(-distances**2 / (2 * sigma**2))\n",
    "    # Optionally, remove self-loops by zeroing out the diagonal\n",
    "    W.fill_diagonal_(0)\n",
    "    # Compute degree matrix\n",
    "    D = to.diag(W.sum(dim=1))\n",
    "    # Graph Laplacian: L = D - W\n",
    "    L = D - W\n",
    "    return L"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81da522c-1d3c-4ed9-9493-4c3ad87fd142",
   "metadata": {},
   "source": [
    "## Load data and process Gaussian model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b3198d7-42b1-47b1-9a25-76c5afda4367",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quaternion_to_rotation_matrix(quaternions):\n",
    "    x = quaternions[:, 1]\n",
    "    y = quaternions[:, 2]\n",
    "    z = quaternions[:, 3]\n",
    "    w = quaternions[:, 0]\n",
    "\n",
    "    xx = x * x\n",
    "    yy = y * y\n",
    "    zz = z * z\n",
    "    xy = x * y\n",
    "    xz = x * z\n",
    "    yz = y * z\n",
    "    xw = x * w\n",
    "    yw = y * w\n",
    "    zw = z * w\n",
    "\n",
    "    n = quaternions.shape[0]\n",
    "    R = to.empty((n, 3, 3), dtype=quaternions.dtype)\n",
    "\n",
    "    R[:, 0, 0] = 1 - 2 * (yy + zz)\n",
    "    R[:, 0, 1] = 2 * (xy - zw)\n",
    "    R[:, 0, 2] = 2 * (xz + yw)\n",
    "    R[:, 1, 0] = 2 * (xy + zw)\n",
    "    R[:, 1, 1] = 1 - 2 * (xx + zz)\n",
    "    R[:, 1, 2] = 2 * (yz - xw)\n",
    "    R[:, 2, 0] = 2 * (xz - yw)\n",
    "    R[:, 2, 1] = 2 * (yz + xw)\n",
    "    R[:, 2, 2] = 1 - 2 * (xx + yy)\n",
    "\n",
    "    return R\n",
    "\n",
    "class GaussianModel:    \n",
    "    def __init__(self, path):\n",
    "        # Load in data\n",
    "        plyfile = PlyData.read(path)\n",
    "        plydata = plyfile['vertex'].data\n",
    "        # Covert data into tensors\n",
    "        df = pd.DataFrame(plydata)\n",
    "        means_mask = [\"x\", \"y\", \"z\"]\n",
    "        quaternions_mask = [\"rot_0\", \"rot_1\", \"rot_2\", \"rot_3\"]\n",
    "        scales_mask = [\"scale_0\", \"scale_1\", \"scale_2\"]\n",
    "        opacities_mask = [\"opacity\"]\n",
    "\n",
    "        self.means = to.tensor(df[means_mask].values)\n",
    "        self.quaternions = to.tensor(df[quaternions_mask].values)\n",
    "        self.scales = to.tensor(df[scales_mask].values)\n",
    "        self.opacities = to.tensor(df[opacities_mask].values)\n",
    "        \n",
    "        # Set base data\n",
    "        self.n_gaussians = plydata.shape[0]\n",
    "\n",
    "        self.means = to.tensor(df[means_mask].values)\n",
    "        self.quaternions = to.tensor(df[quaternions_mask].values)\n",
    "        self.scales = to.tensor(df[scales_mask].values)\n",
    "        self.opacities = to.tensor(df[opacities_mask].values)\n",
    "        \n",
    "        # Activate opacities\n",
    "        self.opacities = 1 / (1 + to.exp(-self.opacities))\n",
    "        # Derive rotation matrix\n",
    "        self.normalised_quaternions = self.quaternions / to.linalg.norm(self.quaternions)\n",
    "        self.rotations = quaternion_to_rotation_matrix(self.normalised_quaternions)\n",
    "        # Derive scale matrix\n",
    "        self.scales_exp = to.exp(self.scales)\n",
    "        self.scales_d = to.eye(3)[None, :, :] * (self.scales_exp)[:, :, None]\n",
    "        self.scales_d **= 2\n",
    "        self.scales_i_d = to.eye(3)[None, :, :] * (1/self.scales_exp)[:, :, None]\n",
    "        self.scales_i_d **= 2\n",
    "        # Derive covariance matrix\n",
    "        self.rotations_t = self.rotations.transpose(-1,-2)\n",
    "        self.scales_d_t = self.scales_d.transpose(-1,-2)\n",
    "        self.covariances = self.rotations @ self.scales_d @ self.rotations_t\n",
    "        # Derive the normals (use the centroid to flip normals correctly.)\n",
    "        min_indices = self.scales_exp.argmin(axis=1)\n",
    "        self.normals = self.rotations[to.arange(self.n_gaussians), :, min_indices]\n",
    "        self.normals = self.normals / to.linalg.norm(self.normals)\n",
    "        centroid = self.means.mean(dim=0)\n",
    "        vectors_to_centroid = centroid - self.means\n",
    "        dot_products = (vectors_to_centroid * self.normals).sum(dim=1)\n",
    "        flip_mask = dot_products < 0\n",
    "        self.normals[flip_mask] = -self.normals[flip_mask]\n",
    "        self.reference_normals = self.normals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50dec73-e9df-4f65-ba39-6e361774de6c",
   "metadata": {},
   "source": [
    "# Projection shit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07ea4bfb-7494-46a7-9cad-0213fc01e5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_points(points, gaussian_means, gaussian_inv_covs, gaussian_opacities):\n",
    "    distance_to_mean = points - gaussian_means\n",
    "    exponent = -0.5 * (distance_to_mean[:,:,None,:] @ gaussian_inv_covs @ distance_to_mean[..., None])\n",
    "    evaluations = gaussian_opacities * to.exp(exponent).squeeze(-1)\n",
    "    return evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59e2484f-0a1c-4f03-941d-df3b4a833969",
   "metadata": {},
   "outputs": [],
   "source": [
    "def skew_symmetric(v):\n",
    "    row1 = to.stack([to.zeros_like(v[..., 0]), -v[..., 2], v[..., 1]], dim=-1)\n",
    "    row2 = to.stack([v[..., 2], to.zeros_like(v[..., 1]), -v[..., 0]], dim=-1)\n",
    "    row3 = to.stack([-v[..., 1], v[..., 0], to.zeros_like(v[..., 2])], dim=-1)\n",
    "    K = to.stack([row1, row2, row3], dim=-2)\n",
    "    return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0575c41-c871-42ab-8963-c478390e82dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normals_to_rot_matrix(a, b):\n",
    "    # Given 2 RxNx3 vectors a and b, return an RxNx3x3 rotation matrix\n",
    "    a_dot_b = (a[:,:,None,:] @ b[..., None]).squeeze(-1).squeeze(-1)\n",
    "    a_norm = to.linalg.norm(a)\n",
    "    b_norm = to.linalg.norm(b,dim=2)\n",
    "    angle = to.acos((a_dot_b / (a_norm * b_norm)))\n",
    "    v = to.cross(a,b)\n",
    "    s = to.norm(v,dim=2) * to.sin(angle)\n",
    "    c = a_dot_b * to.cos(angle) \n",
    "    i = to.eye(3).tile(a.shape[0],a.shape[1],1,1)\n",
    "    v_skew = skew_symmetric(v)\n",
    "    last_term = 1 / (1 + c)\n",
    "    return i + v_skew + (v_skew @ v_skew) * last_term[...,None,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee881bd5-3029-4465-ad14-419ca3fc45a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_responses_and_tvals(\n",
    "    ray_oris, \n",
    "    means, \n",
    "    covs,\n",
    "    ray_dirs, \n",
    "    opacities,\n",
    "    normals,\n",
    "    old_normals\n",
    "):\n",
    "    new_rotations = normals_to_rot_matrix(old_normals, normals)\n",
    "    new_covs = new_rotations @ covs @ new_rotations.transpose(-2,-1)\n",
    "    inv_covs = to.linalg.inv(new_covs)\n",
    "    rg_diff = means - ray_oris\n",
    "    inv_cov_d = inv_covs @ ray_dirs[..., None]\n",
    "    numerator = (rg_diff[:,:,None,:] @ inv_cov_d).squeeze(-1)\n",
    "    denomenator = (ray_dirs[:,:,None,:] @ inv_cov_d).squeeze(-1)\n",
    "    t_values = numerator / denomenator\n",
    "    best_positions = (ray_oris + t_values * ray_dirs)\n",
    "    max_responses = evaluate_points(best_positions, means, inv_covs, opacities)\n",
    "\n",
    "    return max_responses, t_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6c3c632-297b-4981-b952-4558262c8a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "class GaussianParameters(nn.Module):\n",
    "    def __init__(self, path):\n",
    "        super(GaussianParameters, self).__init__()\n",
    "        self.gaussian_model = GaussianModel(path)\n",
    "        self.means = nn.Parameter(self.gaussian_model.means)\n",
    "        self.normals = nn.Parameter(self.gaussian_model.normals)\n",
    "        ray_oris, ray_dirs = generate_sphere_rays(to.tensor([0.0,0.0,0.0]), 10,100)\n",
    "        self.ray_oris = ray_oris\n",
    "        self.ray_dirs = ray_dirs\n",
    "        self.laplacian = compute_graph_laplacian(ray_oris, 1, 10)\n",
    "\n",
    "    def forward(self):\n",
    "        return self.means, self.normals\n",
    "\n",
    "    def project(self):\n",
    "        gaussian_dataset = TensorDataset(\n",
    "            self.means,\n",
    "            self.gaussian_model.covariances,\n",
    "            self.gaussian_model.opacities,\n",
    "            self.normals,\n",
    "            self.gaussian_model.reference_normals\n",
    "        )\n",
    "        rays_dataset = TensorDataset(\n",
    "            self.ray_oris,\n",
    "            self.ray_dirs\n",
    "        )\n",
    "\n",
    "        gaussian_generator = DataLoader(gaussian_dataset, batch_size=10000)\n",
    "        ray_generator = DataLoader(rays_dataset, batch_size=10000)\n",
    "\n",
    "        self.contributions = []\n",
    "        self.alphas = []\n",
    "        self.tvals = []\n",
    "        self.values = []\n",
    "        for ray_batch in ray_generator:\n",
    "            self.alphas_along_ray = []\n",
    "            self.tvals_along_ray = []\n",
    "            for gauss_batch in gaussian_generator:\n",
    "                (bcast_means,\n",
    "                bcast_covariances,\n",
    "                bcast_opacities,\n",
    "                bcast_normals,\n",
    "                bcast_reference_normals,\n",
    "                bcast_ray_oris,\n",
    "                bcast_ray_dirs) = broadcast(gauss_batch, ray_batch)\n",
    "\n",
    "                batch_alphas, batch_tvals = get_max_responses_and_tvals(\n",
    "                    bcast_ray_oris, \n",
    "                    bcast_means, \n",
    "                    bcast_covariances, \n",
    "                    bcast_ray_dirs, \n",
    "                    bcast_opacities,\n",
    "                    bcast_normals,\n",
    "                    bcast_reference_normals\n",
    "                )\n",
    "\n",
    "                \n",
    "                self.alphas_along_ray.append(batch_alphas)\n",
    "                self.tvals_along_ray.append(batch_tvals)\n",
    "                 \n",
    "            self.alphas_along_ray = to.cat(self.alphas_along_ray, dim=1)\n",
    "            self.tvals_along_ray = to.cat(self.tvals_along_ray, dim=1)\n",
    "            self.alphas.append(self.alphas_along_ray)\n",
    "            self.tvals.append(self.tvals_along_ray)\n",
    "\n",
    "            _, sorted_idx = to.sort(self.tvals_along_ray, dim=1)\n",
    "            sorted_alphas = self.alphas_along_ray.gather(dim=1, index=sorted_idx)\n",
    "            alphas_compliment = 1 - sorted_alphas        \n",
    "            transmittance = to.cumprod(alphas_compliment, dim=1)\n",
    "            shifted = to.ones_like(transmittance)\n",
    "            # Fill shifted starting from the second column with the values of x's columns 0 to N-2\n",
    "            shifted[:, 1:] = transmittance[:, :-1]\n",
    "            # Calculate contribution \n",
    "            sorted_contribution = shifted - transmittance\n",
    "            # Normalise\n",
    "            norm_factor = to.sum(sorted_contribution, dim=1)[...,None]\n",
    "            sorted_contribution = sorted_contribution / norm_factor\n",
    "            # unsort the contribution\n",
    "            inv_idx = sorted_idx.argsort(dim=1)\n",
    "            # Reorder contribution back to the original order:\n",
    "            contribution = sorted_contribution.gather(dim=1, index=inv_idx)\n",
    "            self.contributions.append(contribution)\n",
    "            self.values.append(to.sum(contribution * self.alphas_along_ray, dim=1))\n",
    "        self.values = to.cat(self.values, dim=1)\n",
    "        self.alphas = to.cat(self.alphas, dim=1)\n",
    "        self.tvals = to.cat(self.tvals, dim=1)\n",
    "        self.contributions = to.cat(self.contributions, dim=1)\n",
    "        self.blended_tvals = to.sum(self.contributions * self.tvals, dim=1)\n",
    "        return self.blended_tvals\n",
    "    def harmonic_loss(self):\n",
    "        projected_values = self.project() \n",
    "        loss = projected_values.T @ self.laplacian @ projected_values\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1144e2ca-0cca-4886-ab7a-74ec61ff0b9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "543ccd6b-9115-4ecd-a25c-cc9f0772868e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RenderContext():\n",
    "    def __init__(self, width=800, height=600, point_size=0.02):\n",
    "        # Set up scene, camera, and renderer\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.point_size = point_size\n",
    "        self.first_update = False\n",
    "        \n",
    "        # Initialize scene\n",
    "        self.scene = Scene(background=\"#f0f0f0\")\n",
    "        \n",
    "        # Set up camera\n",
    "        self.camera = PerspectiveCamera(\n",
    "            position=[5, 5, 5],\n",
    "            up=[0, 1, 0],\n",
    "            aspect=width/height,\n",
    "            fov=50\n",
    "        )\n",
    "        \n",
    "        # Create renderer\n",
    "        self.controls = OrbitControls(controlling=self.camera)\n",
    "        self.renderer = Renderer(\n",
    "            camera=self.camera,\n",
    "            scene=self.scene,\n",
    "            controls=[self.controls],\n",
    "            width=width,\n",
    "            height=height,\n",
    "            antialias=True\n",
    "        )\n",
    "        \n",
    "        # Add lighting\n",
    "        self.scene.add(AmbientLight(intensity=0.6))\n",
    "        self.scene.add(DirectionalLight(position=[1, 1, 1], intensity=0.4))\n",
    "        self.scene.add(DirectionalLight(position=[-1, -1, -1], intensity=0.4))\n",
    "        \n",
    "        # Add coordinate axes for reference\n",
    "        axesHelper = AxesHelper(size=1)\n",
    "        self.scene.add(axesHelper)\n",
    "        \n",
    "        # Create grid for reference\n",
    "        gridHelper = GridHelper(size=10, divisions=10)\n",
    "        gridHelper.position = [0, -0.01, 0]  # Slightly below the origin\n",
    "        self.scene.add(gridHelper)\n",
    "        \n",
    "        # Initialize point cloud with dummy data (just one point at origin)\n",
    "        positions = np.array([[0, 0, 0]], dtype=np.float32)\n",
    "        colors = np.array([[0.5, 0.5, 0.5]], dtype=np.float32)\n",
    "        \n",
    "        # Setup for the point cloud\n",
    "        self.positions_attr = BufferAttribute(array=positions, normalized=False)\n",
    "        self.colors_attr = BufferAttribute(array=colors, normalized=False)\n",
    "        \n",
    "        point_geo = BufferGeometry(\n",
    "            attributes={\n",
    "                'position': self.positions_attr,\n",
    "                'color': self.colors_attr\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        point_mat = PointsMaterial(\n",
    "            vertexColors='VertexColors',\n",
    "            size=self.point_size,\n",
    "            sizeAttenuation=True\n",
    "        )\n",
    "        \n",
    "        self.points = Points(geometry=point_geo, material=point_mat)\n",
    "        self.scene.add(self.points)\n",
    "        \n",
    "        # Create a colorbar widget\n",
    "        self.colorbar_widget = self._create_colorbar_widget()\n",
    "        \n",
    "        # Package everything together\n",
    "        self.canvas = widgets.VBox([\n",
    "            self.renderer,\n",
    "            self.colorbar_widget\n",
    "        ])\n",
    "    \n",
    "    def _create_colorbar_widget(self):\n",
    "        \"\"\"Create a simple colorbar widget using HTML\"\"\"\n",
    "        # Create a gradient for the colorbar using HTML\n",
    "        gradient_html = \"\"\"\n",
    "        <div style=\"\n",
    "            width: 100%; \n",
    "            height: 20px; \n",
    "            background: linear-gradient(to right, \n",
    "                #0d0887, #41049d, #6a00a8, #8f0da4, #b12a90, \n",
    "                #cc4778, #e16462, #f2844b, #fca636, #fcce25, #f0f921\n",
    "            );\n",
    "            border-radius: 3px;\n",
    "            margin-top: 5px;\n",
    "        \"></div>\n",
    "        <div style=\"\n",
    "            display: flex;\n",
    "            justify-content: space-between;\n",
    "            font-family: Arial;\n",
    "            font-size: 12px;\n",
    "            margin-top: 2px;\n",
    "        \">\n",
    "            <span>Min</span>\n",
    "            <span>Max</span>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        \n",
    "        return widgets.HTML(value=gradient_html)\n",
    "    \n",
    "    def update(self, positions, values, colormap='plasma'):\n",
    "        \"\"\"\n",
    "        Update the point cloud visualization\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        positions : numpy.ndarray or torch.Tensor\n",
    "            Array of 3D positions with shape (N, 3)\n",
    "        values : numpy.ndarray or torch.Tensor\n",
    "            Array of scalar values for coloring with shape (N,) or (N, 1)\n",
    "        colormap : str\n",
    "            Name of the matplotlib colormap to use\n",
    "        \"\"\"\n",
    "        # Convert to numpy if tensor\n",
    "        if isinstance(positions, to.Tensor):\n",
    "            positions = positions.detach().cpu().numpy()\n",
    "        if isinstance(values, to.Tensor):\n",
    "            values = values.detach().cpu().numpy()\n",
    "        \n",
    "        # Safety check\n",
    "        if len(positions) == 0:\n",
    "            return\n",
    "        \n",
    "        # Ensure positions are the right shape\n",
    "        if positions.ndim != 2 or positions.shape[1] != 3:\n",
    "            raise ValueError(f\"Positions must have shape (N, 3), got {positions.shape}\")\n",
    "        \n",
    "        # Ensure values are the right shape (flatten if needed)\n",
    "        if values.ndim > 1:\n",
    "            values = values.flatten()\n",
    "        \n",
    "        # Ensure values length matches positions\n",
    "        if len(values) != len(positions):\n",
    "            raise ValueError(f\"Values length {len(values)} must match positions length {len(positions)}\")\n",
    "            \n",
    "        # Normalize values for coloring\n",
    "        min_val = np.min(values)\n",
    "        max_val = np.max(values)\n",
    "        norm = mcolors.Normalize(vmin=min_val, vmax=max_val)\n",
    "        cmap = cm.get_cmap(colormap)\n",
    "        \n",
    "        # Generate colors from values using the colormap\n",
    "        colors = cmap(norm(values))[:, :3].astype(np.float32)\n",
    "        \n",
    "        # Update positions and colors in the buffer\n",
    "        self.positions_attr.array = positions.astype(np.float32)\n",
    "        self.colors_attr.array = colors\n",
    "        \n",
    "        # Mark attributes as needing update\n",
    "        self.positions_attr.needsUpdate = True\n",
    "        self.colors_attr.needsUpdate = True\n",
    "        \n",
    "        # Update colorbar with new min/max values\n",
    "        self.colorbar_widget.value = f\"\"\"\n",
    "        <div style=\"\n",
    "            width: 100%; \n",
    "            height: 20px; \n",
    "            background: linear-gradient(to right, \n",
    "                #0d0887, #41049d, #6a00a8, #8f0da4, #b12a90, \n",
    "                #cc4778, #e16462, #f2844b, #fca636, #fcce25, #f0f921\n",
    "            );\n",
    "            border-radius: 3px;\n",
    "            margin-top: 5px;\n",
    "        \"></div>\n",
    "        <div style=\"\n",
    "            display: flex;\n",
    "            justify-content: space-between;\n",
    "            font-family: Arial;\n",
    "            font-size: 12px;\n",
    "            margin-top: 2px;\n",
    "        \">\n",
    "            <span>{min_val:.4f}</span>\n",
    "            <span>{max_val:.4f}</span>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        \n",
    "        # Adjust camera if needed (for first update)\n",
    "        if not self.first_update:\n",
    "            # Calculate bounding box of points\n",
    "            min_bounds = np.min(positions, axis=0)\n",
    "            max_bounds = np.max(positions, axis=0)\n",
    "            center = (min_bounds + max_bounds) / 2\n",
    "            \n",
    "            # Set camera to look at center of points\n",
    "            self.controls.target = center.tolist()\n",
    "            \n",
    "            # Reset camera position relative to the center\n",
    "            max_dim = np.max(max_bounds - min_bounds)\n",
    "            camera_dist = max_dim * 2\n",
    "            self.camera.position = [\n",
    "                center[0] + camera_dist,\n",
    "                center[1] + camera_dist,\n",
    "                center[2] + camera_dist\n",
    "            ]\n",
    "            \n",
    "            self.first_update = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "197d77d1-630e-43af-9c84-88d5668f8a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, num_iterations=10000, lr=0.005):\n",
    "    optimizer = to.optim.Adam(model.parameters(), lr=lr)\n",
    "    context = RenderContext()\n",
    "    display(context.canvas)\n",
    "    \n",
    "    for iteration in tqdm(range(num_iterations)):\n",
    "        optimizer.zero_grad()\n",
    "        loss = model.harmonic_loss()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update visualization every few iterations to avoid slowdown\n",
    "        if iteration % 10 == 0:\n",
    "            positions = (model.ray_oris + model.blended_tvals * model.ray_dirs).detach().numpy()\n",
    "            blended_tvals = model.blended_tvals.detach().numpy()\n",
    "            context.update(positions, blended_tvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8741060a-fc57-4005-beef-36a988c77b62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "pythree_example_model_217",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Renderer(camera=PerspectiveCamera(aspect=1.3333333333333333, position=(5.0, 5.0, 5.0), projecti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "pythree_example_model_228",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_853386/856301233.py:145: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  cmap = cm.get_cmap(colormap)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0808]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = GaussianParameters(\"point_cloud.ply\")\n",
    "train_model(model=model, num_iterations=10)\n",
    "print(model.harmonic_loss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b3503d2b-7f18-4217-bee6-734ce960cc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get snapshot : returns current solution using train_model.harmonic_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d304b3e2-f02f-4623-92ed-ef30742cc087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[84.7075]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GaussianParameters('point_cloud.ply')\n",
    "ray_oris, ray_dirs = generate_sphere_rays(to.tensor([0.0,0.0,0.0]), 10.0, 100)\n",
    "laplacian = compute_graph_laplacian(ray_oris, 1.0, 10.0)\n",
    "projected_value = model.project()\n",
    "projected_value.T @ laplacian @ projected_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fff10d1b-a34e-4bc1-8969-68b878744543",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1.0.a16\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'fastplotlib' has no attribute 'Figure'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfastplotlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfpl\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(fpl\u001b[38;5;241m.\u001b[39m__version__)\n\u001b[0;32m----> 7\u001b[0m figure \u001b[38;5;241m=\u001b[39m \u001b[43mfpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFigure\u001b[49m(size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m700\u001b[39m, \u001b[38;5;241m560\u001b[39m))\n\u001b[1;32m      9\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\n\u001b[1;32m     10\u001b[0m     [[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m],\n\u001b[1;32m     11\u001b[0m      [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m]]\n\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     13\u001b[0m image_graphic \u001b[38;5;241m=\u001b[39m figure[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39madd_image(data)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'fastplotlib' has no attribute 'Figure'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# test_example = true\n",
    "\n",
    "import fastplotlib as fpl\n",
    "print(fpl.__version__)\n",
    "figure = fpl.Figure(size=(700, 560))\n",
    "\n",
    "data = np.array(\n",
    "    [[0, 1, 2],\n",
    "     [3, 4, 5]]\n",
    ")\n",
    "image_graphic = figure[0, 0].add_image(data)\n",
    "\n",
    "figure.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462c6d10-4d3e-4715-af08-709407bc221a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e50c12-dae2-49e4-acba-b38a453648c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af63908-1dfb-443c-8b48-7ed69d4aeb45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
