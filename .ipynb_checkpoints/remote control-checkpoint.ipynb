{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2271212",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-8:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/naitobi/miniconda3/envs/env/lib/python3.9/threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/naitobi/miniconda3/envs/env/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/home/naitobi/miniconda3/envs/env/lib/python3.9/threading.py\", line 917, in run\n",
      "  0%|                                                                                                           | 0/1000 [00:00<?, ?it/s]    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_305385/4253061064.py\", line 1047, in start_visualization\n",
      "  File \"/tmp/ipykernel_305385/4253061064.py\", line 1020, in visualize_depth_updates\n",
      "  File \"/home/naitobi/miniconda3/envs/env/lib/python3.9/site-packages/vispy/scene/canvas.py\", line 135, in __init__\n",
      "    super(SceneCanvas, self).__init__(\n",
      "  File \"/home/naitobi/miniconda3/envs/env/lib/python3.9/site-packages/vispy/app/canvas.py\", line 211, in __init__\n",
      "    self.create_native()\n",
      "  File \"/home/naitobi/miniconda3/envs/env/lib/python3.9/site-packages/vispy/app/canvas.py\", line 226, in create_native\n",
      "    assert self._app.native\n",
      "  File \"/home/naitobi/miniconda3/envs/env/lib/python3.9/site-packages/vispy/app/application.py\", line 177, in native\n",
      "    return self._backend._vispy_get_native_app()\n",
      "  File \"/home/naitobi/miniconda3/envs/env/lib/python3.9/site-packages/vispy/app/backends/_glfw.py\", line 210, in _vispy_get_native_app\n",
      "    raise OSError('Could not init glfw:\\n%r' % _glfw_errors)\n",
      "OSError: Could not init glfw:\n",
      "[\"Error 65550: b'X11: The DISPLAY environment variable is missing'\", \"Error 65550: b'X11: The DISPLAY environment variable is missing'\", \"Error 65550: b'X11: The DISPLAY environment variable is missing'\"]\n",
      "  9%|████████▌                                                                                         | 87/1000 [00:05<01:00, 15.10it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1071\u001b[0m\n\u001b[1;32m   1069\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1070\u001b[0m     model \u001b[38;5;241m=\u001b[39m GaussianParameters(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpoint_cloud.ply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1071\u001b[0m     \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_iterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1072\u001b[0m     \u001b[38;5;66;03m# Get spatial grid parameters\u001b[39;00m\n\u001b[1;32m   1073\u001b[0m     \u001b[38;5;66;03m# Call optimized projection function\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 1057\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, num_iterations, lr)\u001b[0m\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m iteration \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(num_iterations)):\n\u001b[1;32m   1056\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m-> 1057\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mharmonic_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1058\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m   1059\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "Cell \u001b[0;32mIn[3], line 730\u001b[0m, in \u001b[0;36mGaussianParameters.harmonic_loss\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mharmonic_loss\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    729\u001b[0m     \u001b[38;5;66;03m# Compute the current projection of t-values.\u001b[39;00m\n\u001b[0;32m--> 730\u001b[0m     blended_t_vals \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproject\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m to\u001b[38;5;241m.\u001b[39misnan(blended_t_vals)\u001b[38;5;241m.\u001b[39many() \u001b[38;5;129;01mor\u001b[39;00m to\u001b[38;5;241m.\u001b[39misinf(blended_t_vals)\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m    733\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaN or Inf detected in blended_t_vals\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[3], line 617\u001b[0m, in \u001b[0;36mGaussianParameters.project\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m    614\u001b[0m ray_gaussian_candidates \u001b[38;5;241m=\u001b[39m ray_gaussian[i:batch_end]\n\u001b[1;32m    616\u001b[0m \u001b[38;5;66;03m# Compute responses and t-values\u001b[39;00m\n\u001b[0;32m--> 617\u001b[0m responses, tvals \u001b[38;5;241m=\u001b[39m \u001b[43mget_max_responses_and_tvals\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_rays\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    619\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmeans\u001b[49m\u001b[43m[\u001b[49m\u001b[43mray_gaussian_candidates\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgaussian_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcovariances\u001b[49m\u001b[43m[\u001b[49m\u001b[43mray_gaussian_candidates\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_dirs\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgaussian_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopacities\u001b[49m\u001b[43m[\u001b[49m\u001b[43mray_gaussian_candidates\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormals\u001b[49m\u001b[43m[\u001b[49m\u001b[43mray_gaussian_candidates\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgaussian_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormals\u001b[49m\u001b[43m[\u001b[49m\u001b[43mray_gaussian_candidates\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    627\u001b[0m responses \u001b[38;5;241m=\u001b[39m to\u001b[38;5;241m.\u001b[39mwhere(responses \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.01\u001b[39m, \n\u001b[1;32m    628\u001b[0m                     responses, \n\u001b[1;32m    629\u001b[0m                     to\u001b[38;5;241m.\u001b[39mzeros_like(responses))\n\u001b[1;32m    631\u001b[0m \u001b[38;5;66;03m# Only compute blended values for rays that have at least some valid contributions\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 375\u001b[0m, in \u001b[0;36mget_max_responses_and_tvals\u001b[0;34m(ray_oris, means, covs, ray_dirs, opacities, normals, old_normals)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_max_responses_and_tvals\u001b[39m(\n\u001b[1;32m    373\u001b[0m     ray_oris, means, covs, ray_dirs, opacities, normals, old_normals\n\u001b[1;32m    374\u001b[0m ):\n\u001b[0;32m--> 375\u001b[0m     new_rotations \u001b[38;5;241m=\u001b[39m \u001b[43mnormals_to_rot_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mold_normals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    376\u001b[0m     new_covs \u001b[38;5;241m=\u001b[39m new_rotations \u001b[38;5;241m@\u001b[39m covs \u001b[38;5;241m@\u001b[39m new_rotations\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    377\u001b[0m     covs_reg \u001b[38;5;241m=\u001b[39m covs \u001b[38;5;241m+\u001b[39m to\u001b[38;5;241m.\u001b[39meye(\u001b[38;5;241m3\u001b[39m, device\u001b[38;5;241m=\u001b[39mcovs\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1e-4\u001b[39m\n",
      "Cell \u001b[0;32mIn[3], line 366\u001b[0m, in \u001b[0;36mnormals_to_rot_matrix\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m    364\u001b[0m s \u001b[38;5;241m=\u001b[39m to\u001b[38;5;241m.\u001b[39mnorm(v, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m*\u001b[39m to\u001b[38;5;241m.\u001b[39msin(angle)\n\u001b[1;32m    365\u001b[0m c \u001b[38;5;241m=\u001b[39m a_dot_b \u001b[38;5;241m*\u001b[39m to\u001b[38;5;241m.\u001b[39mcos(angle)\n\u001b[0;32m--> 366\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[43mto\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meye\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtile(a\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], a\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    367\u001b[0m v_skew \u001b[38;5;241m=\u001b[39m skew_symmetric(v)\n\u001b[1;32m    368\u001b[0m last_term \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m c)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "from plyfile import PlyData, PlyElement\n",
    "import torch.autograd.profiler as profiler\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import math\n",
    "import torch as to\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from vispy import scene, app\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from blank import kernel_code\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "import cupy as cp\n",
    "module = cp.RawModule(code=kernel_code)\n",
    "kernel = module.get_function(\"ray_aabb_intersect_top16\")\n",
    "def broadcast(gauss_batch, ray_batch):\n",
    "    # Split up gauss_batch\n",
    "    means, covariances, opacities, normals, reference_normals = gauss_batch\n",
    "    # Split up ray_batch\n",
    "    ray_oris, ray_dirs = ray_batch\n",
    "\n",
    "    R = ray_oris.shape[0]\n",
    "    G = means.shape[0]\n",
    "\n",
    "    bcast_ray_oris = ray_oris.unsqueeze(1)\n",
    "    # (N_, dim=1rays, 1, 3)\n",
    "    bcast_ray_dirs = ray_dirs.unsqueeze(1)\n",
    "    # (1, N_gaussians, 3)\n",
    "    bcast_means = means.unsqueeze(0)\n",
    "    # (1, N_gaussians, 3)\n",
    "    bcast_covariances = covariances.unsqueeze(0)\n",
    "    # (1, N_gaussians)\n",
    "    bcast_opacities = opacities.unsqueeze(0)\n",
    "    # (1, N_gaussians, 3)\n",
    "    bcast_normals = normals.unsqueeze(0)\n",
    "    # (1, N_gaussians, 3)\n",
    "    bcast_reference_normals = reference_normals.unsqueeze(0)\n",
    "\n",
    "    return (\n",
    "        bcast_means,\n",
    "        bcast_covariances,\n",
    "        bcast_opacities,\n",
    "        bcast_normals,\n",
    "        bcast_reference_normals,\n",
    "        bcast_ray_oris,\n",
    "        bcast_ray_dirs,\n",
    "    )\n",
    "\n",
    "\n",
    "def generate_fibonacci_sphere_rays(center, radius, n, jitter_scale=0.03):\n",
    "    \"\"\"\n",
    "    Generate rays using Fibonacci sphere sampling with PyTorch vectorization.\n",
    "    Adds random jitter to ray directions for more natural variation.\n",
    "\n",
    "    Args:\n",
    "        center: The center point of the sphere (to tensor of shape [3])\n",
    "        radius: The radius of the sphere\n",
    "        n: Number of points/rays to generate\n",
    "        jitter_scale: Scale factor for jitter (0.0 = no jitter)\n",
    "\n",
    "    Returns:\n",
    "        ray_oris: Ray origins on the sphere surface\n",
    "        ray_dirs: Ray directions (normalized vectors pointing outward from center)\n",
    "    \"\"\"\n",
    "    # Create indices tensor\n",
    "    indices = to.arange(0, n, dtype=to.float32)\n",
    "\n",
    "    # Calculate z coordinates (vectorized)\n",
    "    z = 1 - (2 * indices) / (n - 1) if n > 1 else to.zeros(1)\n",
    "\n",
    "    # Calculate radius at each height (vectorized)\n",
    "    r = to.sqrt(1 - z * z)\n",
    "\n",
    "    # Golden ratio for Fibonacci spiral\n",
    "    phi = (1 + math.sqrt(5)) / 2\n",
    "\n",
    "    # Calculate theta (vectorized)\n",
    "    theta = 2 * math.pi * indices / phi\n",
    "\n",
    "    # Calculate x and y coordinates (vectorized)\n",
    "    x = r * to.cos(theta)\n",
    "    y = r * to.sin(theta)\n",
    "\n",
    "    # Stack to create ray origins\n",
    "    ray_oris = to.stack([x, y, z], dim=1)\n",
    "\n",
    "    # Scale by radius\n",
    "    ray_oris = ray_oris * radius\n",
    "\n",
    "    # Add center offset\n",
    "    ray_oris = ray_oris + center\n",
    "\n",
    "    # Ray directions pointing outward from the center\n",
    "    ray_dirs = center - ray_oris\n",
    "    \n",
    "    # Add random jitter to ray directions\n",
    "    if jitter_scale > 0:\n",
    "        jitter = to.randn_like(ray_dirs) * jitter_scale\n",
    "        ray_dirs = ray_dirs + jitter\n",
    "\n",
    "    # Normalize ray directions\n",
    "    ray_dirs = ray_dirs / to.linalg.norm(ray_dirs, dim=1, keepdim=True)\n",
    "\n",
    "    return ray_oris, ray_dirs\n",
    "\n",
    "\n",
    "def generate_sphere_rays(center, radius, n):\n",
    "    # Generate random angles for spherical coordinates\n",
    "    theta = to.rand(n, 1) * 2 * to.pi  # Azimuthal angle\n",
    "    phi = to.rand(n, 1) * to.pi  # Polar angle\n",
    "\n",
    "    # Spherical to Cartesian conversion\n",
    "    x = radius * to.sin(phi) * to.cos(theta)\n",
    "    y = radius * to.sin(phi) * to.sin(theta)\n",
    "    z = radius * to.cos(phi)\n",
    "\n",
    "    # Combine into ray origins\n",
    "    ray_oris = to.hstack((x, y, z))\n",
    "\n",
    "    # Ray directions pointing outward from the center\n",
    "    ray_dirs = ray_oris - center\n",
    "    # Normalise ray dirs\n",
    "    ray_dirs = ray_dirs / to.linalg.norm(ray_dirs)\n",
    "\n",
    "    return ray_oris, ray_dirs\n",
    "\n",
    "\n",
    "def compute_pairwise_great_circle(points, radius=1.0):\n",
    "    # Normalize points to lie on the unit sphere\n",
    "    points_normalized = points / points.norm(dim=1, keepdim=True)\n",
    "    # Compute the pairwise dot product; for unit vectors, this equals cos(theta)\n",
    "    dot_prod = to.mm(points_normalized, points_normalized.t())\n",
    "    # Clamp to ensure numerical stability\n",
    "    dot_prod = to.clamp(dot_prod, -1.0, 1.0)\n",
    "    # Compute the great circle distance (angle in radians)\n",
    "    distances = to.acos(dot_prod)\n",
    "    # Scale by the sphere's radius if needed\n",
    "    return distances * radius\n",
    "\n",
    "def compute_pairwise_euclidean(points):\n",
    "    \"\"\"\n",
    "    Compute pairwise Euclidean distances for an (N,3) tensor of points.\n",
    "    \"\"\"\n",
    "    # (points^2).sum(1) => shape (N,)\n",
    "    # Expand dims for row-column broadcast => shape (N,1), then (1,N)\n",
    "    sum_sq = (points**2).sum(dim=1, keepdim=True)\n",
    "    # Pairwise squared distances\n",
    "    sq_dists = sum_sq + sum_sq.T - 2.0 * (points @ points.T)\n",
    "    sq_dists = to.clamp(sq_dists, min=0.0)  # numerical stability\n",
    "    return to.sqrt(sq_dists)\n",
    "\n",
    "\n",
    "def compute_graph_laplacian(points, scale=5.0):\n",
    "   # Get pairwise Euclidean distances (N x N)\n",
    "    dists = compute_pairwise_euclidean(points)\n",
    "    \n",
    "    # Compute weight matrix, applying the exponential decay.\n",
    "    W = to.exp(-dists / scale)\n",
    "    \n",
    "    # Remove self connections by zeroing the diagonal.\n",
    "    n = points.shape[0]\n",
    "    eye = to.eye(n, device=points.device)\n",
    "    W = W * (1 - eye)\n",
    "    \n",
    "    # Build degree matrix D.\n",
    "    D = to.diag(W.sum(dim=1))\n",
    "    \n",
    "    # Compute Laplacian L = D - W.\n",
    "    L = D - W\n",
    "    \n",
    "    return L\n",
    "\n",
    "\n",
    "def quaternion_to_rotation_matrix(quaternions):\n",
    "    x = quaternions[:, 1]\n",
    "    y = quaternions[:, 2]\n",
    "    z = quaternions[:, 3]\n",
    "    w = quaternions[:, 0]\n",
    "\n",
    "    xx = x * x\n",
    "    yy = y * y\n",
    "    zz = z * z\n",
    "    xy = x * y\n",
    "    xz = x * z\n",
    "    yz = y * z\n",
    "    xw = x * w\n",
    "    yw = y * w\n",
    "    zw = z * w\n",
    "\n",
    "    n = quaternions.shape[0]\n",
    "    R = to.empty((n, 3, 3), dtype=quaternions.dtype)\n",
    "\n",
    "    R[:, 0, 0] = 1 - 2 * (yy + zz)\n",
    "    R[:, 0, 1] = 2 * (xy - zw)\n",
    "    R[:, 0, 2] = 2 * (xz + yw)\n",
    "    R[:, 1, 0] = 2 * (xy + zw)\n",
    "    R[:, 1, 1] = 1 - 2 * (xx + zz)\n",
    "    R[:, 1, 2] = 2 * (yz - xw)\n",
    "    R[:, 2, 0] = 2 * (xz - yw)\n",
    "    R[:, 2, 1] = 2 * (yz + xw)\n",
    "    R[:, 2, 2] = 1 - 2 * (xx + yy)\n",
    "\n",
    "    return R\n",
    "\n",
    "\n",
    "class GaussianModel:\n",
    "    def __init__(self, path):\n",
    "        self.path = path  # store original path for later saving\n",
    "        # Load in data\n",
    "        plyfile = PlyData.read(path)\n",
    "        plydata = plyfile[\"vertex\"].data\n",
    "        df = pd.DataFrame(plydata)\n",
    "        means_mask = [\"x\", \"y\", \"z\"]\n",
    "        quaternions_mask = [\"rot_0\", \"rot_1\", \"rot_2\", \"rot_3\"]\n",
    "        scales_mask = [\"scale_0\", \"scale_1\", \"scale_2\"]\n",
    "        opacities_mask = [\"opacity\"]\n",
    "\n",
    "        self.means = to.tensor(df[means_mask].values).to(device)\n",
    "        self.quaternions = to.tensor(df[quaternions_mask].values).to(device)\n",
    "        self.scales = to.tensor(df[scales_mask].values).to(device)\n",
    "        self.opacities = to.tensor(df[opacities_mask].values).to(device)\n",
    "\n",
    "        self.n_gaussians = plydata.shape[0]\n",
    "\n",
    "        # (repeat loading of data, activation, etc.)\n",
    "        self.opacities = 1 / (1 + to.exp(-self.opacities))\n",
    "        self.normalised_quaternions = self.quaternions / to.linalg.norm(\n",
    "            self.quaternions\n",
    "        )\n",
    "        self.rotations = quaternion_to_rotation_matrix(self.normalised_quaternions).to(\n",
    "            device\n",
    "        )\n",
    "        self.scales_exp = to.exp(self.scales)\n",
    "        self.scales_d = to.eye(3)[None, :, :].to(\n",
    "            device) * (self.scales_exp)[:, :, None]\n",
    "        self.scales_d **= 2\n",
    "        self.scales_i_d = (\n",
    "            to.eye(3)[None, :, :].to(device) *\n",
    "            (1 / self.scales_exp)[:, :, None]\n",
    "        )\n",
    "        self.scales_i_d **= 2\n",
    "        self.rotations_t = self.rotations.transpose(-1, -2)\n",
    "        self.scales_d_t = self.scales_d.transpose(-1, -2)\n",
    "        self.covariances = self.rotations @ self.scales_d @ self.rotations_t\n",
    "\n",
    "        min_indices = self.scales_exp.argmin(axis=1)\n",
    "        self.normals = self.rotations[to.arange(\n",
    "            self.n_gaussians), :, min_indices]\n",
    "        self.normals = self.normals / to.linalg.norm(self.normals)\n",
    "        centroid = self.means.mean(dim=0)\n",
    "        vectors_to_centroid = centroid - self.means\n",
    "        dot_products = (vectors_to_centroid * self.normals).sum(dim=1)\n",
    "        flip_mask = dot_products < 0\n",
    "        self.normals[flip_mask] = -self.normals[flip_mask]\n",
    "        self.reference_normals = self.normals\n",
    "\n",
    "\n",
    "def evaluate_points(points, gaussian_means, gaussian_inv_covs, gaussian_opacities):\n",
    "    distance_to_mean = points - gaussian_means\n",
    "    exponent = -0.5 * (\n",
    "        distance_to_mean[:, :, None, :]\n",
    "        @ gaussian_inv_covs\n",
    "        @ distance_to_mean[..., None]\n",
    "    )\n",
    "    evaluations = gaussian_opacities * to.exp(exponent).squeeze(-1)\n",
    "    return evaluations\n",
    "\n",
    "\n",
    "def skew_symmetric(v):\n",
    "    row1 = to.stack([to.zeros_like(v[..., 0]), -v[..., 2], v[..., 1]], dim=-1)\n",
    "    row2 = to.stack([v[..., 2], to.zeros_like(v[..., 1]), -v[..., 0]], dim=-1)\n",
    "    row3 = to.stack([-v[..., 1], v[..., 0], to.zeros_like(v[..., 2])], dim=-1)\n",
    "    K = to.stack([row1, row2, row3], dim=-2)\n",
    "    return K\n",
    "\n",
    "\n",
    "def normals_to_rot_matrix_2(a, b):\n",
    "    # a and b are assumed to be unit vectors (with shape [..., 3])\n",
    "    # Compute the angle between a and b\n",
    "    a_dot_b = (a * b).sum(dim=-1, keepdim=True)  # shape [..., 1]\n",
    "    theta = to.acos(to.clamp(a_dot_b, -1.0, 1.0))\n",
    "\n",
    "    # Compute the normalized cross product (rotation axis)\n",
    "    v = to.cross(a, b)\n",
    "    v_norm = to.norm(v, dim=-1, keepdim=True)\n",
    "    # To avoid division by zero, add a small epsilon\n",
    "    eps = 1e-8\n",
    "    v_unit = v / (v_norm + eps)\n",
    "\n",
    "    # Build the skew-symmetric matrix from the normalized axis\n",
    "    K = skew_symmetric(v_unit)\n",
    "\n",
    "    # Rodrigues formula: R = I + sin(theta)*K + (1 - cos(theta)) * K^2\n",
    "    I = to.eye(3, device=a.device).expand(a.shape[:-1] + (3, 3))\n",
    "    sin_theta = to.sin(theta)[..., None]\n",
    "    cos_theta = to.cos(theta)[..., None]\n",
    "\n",
    "    R = I + sin_theta * K + (1 - cos_theta) * (K @ K)\n",
    "    return R\n",
    "\n",
    "\n",
    "def axis_angle_to_quaternion(axis, angle):\n",
    "    \"\"\"Convert an axis-angle rotation to a quaternion.\n",
    "    Axis should be normalized.\n",
    "    Returns a quaternion in (w, x, y, z) order.\n",
    "    \"\"\"\n",
    "    half_angle = angle / 2.0\n",
    "    w = to.cos(half_angle)\n",
    "    xyz = axis * to.sin(half_angle)\n",
    "    return to.cat([w, xyz], dim=-1)\n",
    "\n",
    "\n",
    "def compute_difference_quaternion(ref_normals, current_normals, eps=1e-8):\n",
    "    \"\"\"Compute the quaternion that rotates ref_normals to current_normals.\n",
    "    Both inputs are assumed to be normalized and of shape (N, 3).\n",
    "    Returns a tensor of shape (N, 4) representing quaternions in (w, x, y, z) order.\n",
    "    \"\"\"\n",
    "    # Compute the dot product and clamp for stability.\n",
    "    dot = to.clamp((ref_normals * current_normals).sum(dim=-1), -1.0, 1.0)\n",
    "    angle = to.acos(dot)\n",
    "\n",
    "    # Compute the rotation axis.\n",
    "    axis = to.cross(ref_normals, current_normals)\n",
    "    axis_norm = to.norm(axis, dim=-1, keepdim=True)\n",
    "    # Avoid division by zero by providing a default axis when the norm is very small.\n",
    "    axis = to.where(\n",
    "        axis_norm < eps,\n",
    "        to.tensor([1.0, 0.0, 0.0], device=axis.device).expand_as(axis),\n",
    "        axis / (axis_norm + eps),\n",
    "    )\n",
    "\n",
    "    return axis_angle_to_quaternion(axis, angle[..., None])\n",
    "\n",
    "\n",
    "def quaternion_multiply(q, r):\n",
    "    \"\"\"\n",
    "    Multiply two quaternions.\n",
    "    Both q and r are tensors of shape (..., 4) in (w, x, y, z) order.\n",
    "    Returns their product.\n",
    "    \"\"\"\n",
    "    w1, x1, y1, z1 = q.unbind(dim=-1)\n",
    "    w2, x2, y2, z2 = r.unbind(dim=-1)\n",
    "    w = w1 * w2 - x1 * x2 - y1 * y2 - z1 * z2\n",
    "    x = w1 * x2 + x1 * w2 + y1 * z2 - z1 * y2\n",
    "    y = w1 * y2 - x1 * z2 + y1 * w2 + z1 * x2\n",
    "    z = w1 * z2 + x1 * y2 - y1 * x2 + z1 * w2\n",
    "    return to.stack([w, x, y, z], dim=-1)\n",
    "\n",
    "\n",
    "def normals_to_rot_matrix(a, b):\n",
    "    # Given 2 RxNx3 vectors a and b, return an RxNx3x3 rotation matrix\n",
    "    a_dot_b = (a[:, :, None, :] @ b[..., None]).squeeze(-1).squeeze(-1)\n",
    "    a_norm = to.linalg.norm(a)\n",
    "    b_norm = to.linalg.norm(b, dim=2)\n",
    "    angle = to.acos((a_dot_b / (a_norm * b_norm)))\n",
    "    v = to.cross(a, b)\n",
    "    s = to.norm(v, dim=2) * to.sin(angle)\n",
    "    c = a_dot_b * to.cos(angle)\n",
    "    i = to.eye(3).to(device=\"cuda\").tile(a.shape[0], a.shape[1], 1, 1)\n",
    "    v_skew = skew_symmetric(v)\n",
    "    last_term = 1 / (1 + c)\n",
    "    return i + v_skew + (v_skew @ v_skew) * last_term[..., None, None]\n",
    "\n",
    "\n",
    "def get_max_responses_and_tvals(\n",
    "    ray_oris, means, covs, ray_dirs, opacities, normals, old_normals\n",
    "):\n",
    "    new_rotations = normals_to_rot_matrix(old_normals, normals)\n",
    "    new_covs = new_rotations @ covs @ new_rotations.transpose(-2, -1)\n",
    "    covs_reg = covs + to.eye(3, device=covs.device).unsqueeze(0).unsqueeze(0) * 1e-4\n",
    "    inv_covs = to.linalg.inv(covs_reg)\n",
    "    rg_diff = means - ray_oris\n",
    "    inv_cov_d = inv_covs @ ray_dirs[..., None]\n",
    "    numerator = (rg_diff[:, :, None, :] @ inv_cov_d).squeeze(-1)\n",
    "    denomenator = (ray_dirs[:, :, None, :] @ inv_cov_d).squeeze(-1)\n",
    "    t_values = numerator / (denomenator + 1e-8)  # Increase epsilon to 1e-5 or more\n",
    "    best_positions = ray_oris + t_values * ray_dirs\n",
    "    max_responses = evaluate_points(best_positions, means, inv_covs, opacities)\n",
    "\n",
    "    return max_responses, t_values\n",
    "\n",
    "\n",
    "class GaussianParameters(nn.Module):\n",
    "    def __init__(self, path):\n",
    "        super(GaussianParameters, self).__init__()\n",
    "        self.gaussian_model = GaussianModel(path)\n",
    "        self.means = nn.Parameter(self.gaussian_model.means)\n",
    "        self.normals = self.gaussian_model.normals\n",
    "        ray_oris, ray_dirs = generate_fibonacci_sphere_rays(\n",
    "            to.tensor([0.0, 0.0, 0.0]), 1, 2000\n",
    "        )\n",
    "        self.ray_oris = ray_oris.to(device)\n",
    "        self.ray_dirs = ray_dirs.to(device)\n",
    "        self.laplacian = compute_graph_laplacian(ray_oris).to(device)\n",
    "\n",
    "    def forward(self):\n",
    "        return self.means\n",
    "    \n",
    "    def create_bounding_boxes(self):\n",
    "        unit_cube = to.tensor(\n",
    "            [\n",
    "                [1.0, 1.0, 1.0],\n",
    "                [-1.0, -1.0, -1.0],\n",
    "            ],\n",
    "            device=device,\n",
    "        )\n",
    "\n",
    "        # Shape: (N, 2, 3)\n",
    "        scaled_vertices = (\n",
    "            self.gaussian_model.scales_exp[:, None, :] * unit_cube[None, :, :]\n",
    "        )\n",
    "        '''\n",
    "        new_rotations = normals_to_rot_matrix(\n",
    "            self.gaussian_model.reference_normals[None,\n",
    "                                                  :], self.normals[None, :]\n",
    "        )\n",
    "        new_rotations = new_rotations.squeeze(0)\n",
    "        '''\n",
    "        # Expand rotations to match the number of vertices (2)\n",
    "        rotation_expanded = self.gaussian_model.rotations.unsqueeze(\n",
    "            1)  # [N, 1, 3, 3]\n",
    "        # [N, 2, 3, 3]\n",
    "\n",
    "        rotation_expanded = rotation_expanded.expand(-1, 2, -1, -1)\n",
    "\n",
    "        # Now do the matrix multiplication\n",
    "        rotated_vertices = (\n",
    "            rotation_expanded @ scaled_vertices[..., None]\n",
    "        )  # [N, 2, 3, 1]\n",
    "        rotated_vertices = rotated_vertices.squeeze(-1)  # [N, 2, 3]\n",
    "\n",
    "        # Finally translate\n",
    "        translated = rotated_vertices + self.means[:, None, :]\n",
    "        return translated.min(dim=1).values, translated.max(dim=1).values\n",
    "    \n",
    "    def get_top_16(self, ray_oris, ray_dirs, min_corners, max_corners):\n",
    "        num_rays = ray_oris.shape[0]\n",
    "        num_boxes = min_corners.shape[0]\n",
    "\n",
    "        # Create an output tensor for indices\n",
    "        out_indices = to.full((num_rays, 32), -1, device=ray_oris.device, dtype=to.int32)\n",
    "\n",
    "        # Get device pointers\n",
    "        ray_ori_ptr      = ray_oris.data_ptr()\n",
    "        ray_dir_ptr      = ray_dirs.data_ptr()\n",
    "        min_corners_ptr  = min_corners.data_ptr()\n",
    "        max_corners_ptr  = max_corners.data_ptr()\n",
    "        out_indices_ptr  = out_indices.data_ptr()\n",
    "\n",
    "        threads_per_block = 256         \n",
    "        blocks = (num_rays + threads_per_block - 1) // threads_per_block\n",
    "\n",
    "        # Launch the kernel\n",
    "        kernel((blocks,), (threads_per_block,), \n",
    "            (ray_ori_ptr, ray_dir_ptr, min_corners_ptr, max_corners_ptr,\n",
    "                out_indices_ptr, num_rays, num_boxes))\n",
    "        \n",
    "        valid_mask = out_indices != -1\n",
    "        return out_indices.long(), valid_mask\n",
    "\n",
    "    def get_spatial_hashes(self, x_idxs, y_idxs, z_idxs, spatial_args):\n",
    "        h = (x_idxs * 8191) ^ (y_idxs * 131071) ^ (z_idxs * 524287)\n",
    "        return to.abs(h) % spatial_args[\"num_cells\"]\n",
    "\n",
    "    def ray_box_intersections(self, spatial_args):\n",
    "        inv_dir = 1.0 / to.where(self.ray_dirs != 0, self.ray_dirs, 1e-8)\n",
    "        t1 = (spatial_args[\"min_corner\"] - self.ray_oris) * inv_dir\n",
    "        t2 = (spatial_args[\"max_corner\"] - self.ray_oris) * inv_dir\n",
    "\n",
    "        t_near, _ = to.max(to.minimum(t1, t2), dim=1)\n",
    "        t_far, _ = to.min(to.maximum(t1, t2), dim=1)\n",
    "        no_hit = t_near > t_far\n",
    "        t_near[no_hit] = to.inf\n",
    "        t_far[no_hit] = to.inf\n",
    "\n",
    "        return t_near, t_far\n",
    "\n",
    "    def ray_box_intersections_binary(self, box_mins, box_maxs, ray_oris, ray_dirs):\n",
    "        \"\"\"\n",
    "        Given:\n",
    "            box_mins: Tensor of shape [B, 3] with each box's minimum corner.\n",
    "            box_maxs: Tensor of shape [B, 3] with each box's maximum corner.\n",
    "            ray_oris: Tensor of shape [R, 3] with ray origins.\n",
    "            ray_dirs: Tensor of shape [R, 3] with normalized ray directions.\n",
    "\n",
    "        Returns:\n",
    "            A tensor of shape [R, B] with 1 if ray i intersects box j, and 0 otherwise.\n",
    "        \"\"\"\n",
    "        device = ray_oris.device\n",
    "        R = ray_oris.shape[0]\n",
    "        B = box_mins.shape[0]\n",
    "\n",
    "        # Expand rays and boxes for vectorized computation.\n",
    "        # ray_oris_exp: [R, 1, 3], ray_dirs_exp: [R, 1, 3]\n",
    "        # box_mins_exp: [1, B, 3], box_maxs_exp: [1, B, 3]\n",
    "        ray_oris_exp = ray_oris.unsqueeze(1)\n",
    "        ray_dirs_exp = ray_dirs.unsqueeze(1)\n",
    "        box_mins_exp = box_mins.unsqueeze(0)\n",
    "        box_maxs_exp = box_maxs.unsqueeze(0)\n",
    "\n",
    "        # Avoid division by zero by replacing zeros in ray_dirs with a small number.\n",
    "        safe_ray_dirs = to.where(\n",
    "            ray_dirs_exp != 0, ray_dirs_exp, to.tensor(1e-8, device=device)\n",
    "        )\n",
    "\n",
    "        t1 = (box_mins_exp - ray_oris_exp) / safe_ray_dirs  # [R, B, 3]\n",
    "        t2 = (box_maxs_exp - ray_oris_exp) / safe_ray_dirs  # [R, B, 3]\n",
    "\n",
    "        # For each dimension, the entry and exit times.\n",
    "        t_min_dim = to.minimum(t1, t2)  # [R, B, 3]\n",
    "        t_max_dim = to.maximum(t1, t2)  # [R, B, 3]\n",
    "\n",
    "        # For each ray-box pair, the overall entry time (largest of the three t_min)\n",
    "        # and exit time (smallest of the three t_max).\n",
    "        t_min = t_min_dim.amax(dim=2)  # [R, B]\n",
    "        t_max = t_max_dim.amin(dim=2)  # [R, B]\n",
    "\n",
    "        # A ray intersects the box if t_max >= max(t_min, 0)\n",
    "        # (i.e. the exit time is positive and occurs after the entry time).\n",
    "        intersects = (t_max >= to.maximum(\n",
    "            t_min, to.zeros_like(t_min))) & (t_max >= 0)\n",
    "        return intersects\n",
    "\n",
    "    def visualize_bounding_volumes_intersections(self):\n",
    "        \"\"\"\n",
    "        Visualize all cell bounding volumes as points (using their centers) colored based\n",
    "        on whether any ray intersects them. Cells intersected by at least one ray are rendered red,\n",
    "        while cells with no intersection are rendered blue.\n",
    "\n",
    "        Returns:\n",
    "            RenderContext: A Vispy render context with the visualization.\n",
    "        \"\"\"\n",
    "        spatial_args = self.get_spatial_args()\n",
    "        box_mins, box_maxs = self.compute_cell_bounding_volumes(spatial_args)\n",
    "        # Compute binary intersections (shape: [R, B] where B is the number of cells).\n",
    "        intersections = self.ray_box_intersections_binary(\n",
    "            box_mins, box_maxs, self.ray_oris, self.ray_dirs\n",
    "        )\n",
    "        # For each cell (axis=0), determine if at least one ray hit it.\n",
    "        cell_intersected = intersections.sum(dim=0) > 0\n",
    "\n",
    "        # Compute cell centers to represent each bounding volume.\n",
    "        cell_centers = box_mins + 0.5 * spatial_args[\"spacings\"]  # [B, 3]\n",
    "        cell_centers_np = cell_centers.detach().cpu().numpy()\n",
    "        cell_intersected_np = cell_intersected.detach().cpu().numpy()\n",
    "\n",
    "        # Create colors: red for intersected cells, blue otherwise.\n",
    "        colors = np.empty((cell_centers_np.shape[0], 4), dtype=np.float32)\n",
    "        colors[cell_intersected_np] = np.array([1, 0, 0, 1], dtype=np.float32)\n",
    "        colors[~cell_intersected_np] = np.array([0, 0, 1, 1], dtype=np.float32)\n",
    "\n",
    "        # Create a RenderContext and set the cell centers (as points).\n",
    "        context = RenderContext(point_size=8)\n",
    "        context.scatter.set_data(\n",
    "            cell_centers_np, face_color=colors, size=context.point_size\n",
    "        )\n",
    "\n",
    "        # Now, draw the rays as lines from their origin to the center.\n",
    "        # Assume the center is at [0,0,0] (as used in your Fibonacci sphere generation).\n",
    "        ray_oris_np = self.ray_oris.detach().cpu().numpy()\n",
    "        N = ray_oris_np.shape[0]\n",
    "        center_np = np.array([0, 0, 0], dtype=np.float32)\n",
    "        # Create an array where each ray contributes 2 points: [origin, center]\n",
    "        line_pos = np.empty((2 * N, 3), dtype=np.float32)\n",
    "        line_pos[0::2] = ray_oris_np\n",
    "        line_pos[1::2] = np.tile(center_np, (N, 1))\n",
    "        # Create connectivity: each segment connects indices 0-1, 2-3, etc.\n",
    "        connect = np.array([[i * 2, i * 2 + 1] for i in range(N)])\n",
    "\n",
    "        # Create a Line visual for the rays.\n",
    "        ray_lines = scene.visuals.Line(\n",
    "            pos=line_pos,\n",
    "            connect=connect,\n",
    "            color=(0, 1, 0, 1),\n",
    "            width=2,\n",
    "            parent=context.view.scene,\n",
    "        )\n",
    "\n",
    "        context.canvas.update()\n",
    "        return context\n",
    "\n",
    "\n",
    "    def project(self, batch_size=1024):\n",
    "        \"\"\"\n",
    "        Process rays in batches to efficiently handle large ray counts\n",
    "        while avoiding memory issues.\n",
    "        \n",
    "        Args:\n",
    "            batch_size: Number of rays to process in each batch\n",
    "            \n",
    "        Returns:\n",
    "            Tensor of blended t-values for all rays\n",
    "        \"\"\"\n",
    "        num_rays = self.ray_oris.shape[0]\n",
    "        all_blended_tvals = []\n",
    "\n",
    "        min_corners, max_corners = self.create_bounding_boxes()\n",
    "\n",
    "        ray_gaussian = self.get_top_16_differentiable()\n",
    "        \n",
    "        # Process rays in batches\n",
    "        for i in range(0, num_rays, batch_size):\n",
    "            batch_end = min(i + batch_size, num_rays)\n",
    "            batch_rays = self.ray_oris[i:batch_end]\n",
    "            batch_dirs = self.ray_dirs[i:batch_end]\n",
    "            \n",
    "            ray_gaussian_candidates = ray_gaussian[i:batch_end]\n",
    "            \n",
    "            # Compute responses and t-values\n",
    "            responses, tvals = get_max_responses_and_tvals(\n",
    "                batch_rays[:, None, :],\n",
    "                self.means[ray_gaussian_candidates],\n",
    "                self.gaussian_model.covariances[ray_gaussian_candidates],\n",
    "                batch_dirs[:, None, :],\n",
    "                self.gaussian_model.opacities[ray_gaussian_candidates],\n",
    "                self.normals[ray_gaussian_candidates],\n",
    "                self.gaussian_model.normals[ray_gaussian_candidates],\n",
    "            )\n",
    "\n",
    "            responses = to.where(responses > 0.01, \n",
    "                                responses, \n",
    "                                to.zeros_like(responses))\n",
    "                \n",
    "            # Only compute blended values for rays that have at least some valid contributions\n",
    "            valid_rays = responses.sum(dim=1) > 0\n",
    "            # Sort by t-values\n",
    "            _, sorted_idx = to.sort(tvals, dim=1)\n",
    "            sorted_alphas = responses.gather(dim=1, index=sorted_idx)\n",
    "            \n",
    "            # Calculate transmittance\n",
    "            alphas_compliment = 1 - sorted_alphas\n",
    "            transmittance = to.cumprod(alphas_compliment, dim=1)\n",
    "            shifted = to.ones_like(transmittance)\n",
    "            shifted[:, 1:] = transmittance[:, :-1]\n",
    "            \n",
    "            # Calculate contribution and blend\n",
    "            sorted_contribution = shifted - transmittance\n",
    "            inv_idx = sorted_idx.argsort(dim=1)\n",
    "            contribution = sorted_contribution.gather(dim=1, index=inv_idx)\n",
    "            batch_blended_tvals = to.sum(contribution * tvals, dim=1)\n",
    "            \n",
    "            all_blended_tvals.append(batch_blended_tvals)\n",
    "        \n",
    "        # Combine results from all batches\n",
    "        return to.cat(all_blended_tvals, dim=0)\n",
    "\n",
    "    def _get_top_16_for_batch(self, batch_rays, batch_dirs):\n",
    "        \"\"\"\n",
    "        Get top 16 closest Gaussians for a batch of rays\n",
    "        \"\"\"\n",
    "        min_corners, max_corners = self.create_bounding_boxes()\n",
    "        \n",
    "        # Expand dimensions for broadcasting\n",
    "        ray_oris_exp = batch_rays.unsqueeze(1)              # [B, 1, 3]\n",
    "        ray_dirs_exp = batch_dirs.unsqueeze(1)              # [B, 1, 3]\n",
    "        min_corners_exp = min_corners.unsqueeze(0)          # [1, G, 3]\n",
    "        max_corners_exp = max_corners.unsqueeze(0)          # [1, G, 3]\n",
    "\n",
    "        return top_16_\n",
    "        \n",
    "    def get_top_16_differentiable(self):\n",
    "        \"\"\"\n",
    "        Differentiable PyTorch implementation of ray-box intersection that returns \n",
    "        indices of the 16 closest bounding boxes for each ray.\n",
    "        \n",
    "        Returns:\n",
    "            torch.Tensor: Indices of shape [num_rays, 16] with the closest box indices\n",
    "        \"\"\"\n",
    "        # Get ray origins, directions, and bounding box corners\n",
    "        ray_oris = self.ray_oris                          # [R, 3]\n",
    "        ray_dirs = self.ray_dirs                          # [R, 3]\n",
    "        min_corners, max_corners = self.create_bounding_boxes()  # [B, 3], [B, 3]\n",
    "        \n",
    "        # Get dimensions\n",
    "        num_rays = ray_oris.shape[0]\n",
    "        num_boxes = min_corners.shape[0]\n",
    "        \n",
    "        # Expand dimensions for broadcasting\n",
    "        ray_oris_exp = ray_oris.unsqueeze(1)              # [R, 1, 3]\n",
    "        ray_dirs_exp = ray_dirs.unsqueeze(1)              # [R, 1, 3]\n",
    "        min_corners_exp = min_corners.unsqueeze(0)        # [1, B, 3]\n",
    "        max_corners_exp = max_corners.unsqueeze(0)        # [1, B, 3]\n",
    "        \n",
    "        # Compute safe reciprocal of ray directions (handle zeros)\n",
    "        safe_ray_dirs = to.where(ray_dirs_exp != 0, ray_dirs_exp, \n",
    "                                to.full_like(ray_dirs_exp, 1e-8))\n",
    "        inv_dirs = 1.0 / safe_ray_dirs                    # [R, 1, 3]\n",
    "        \n",
    "        # Compute t values for each corner\n",
    "        t1 = (min_corners_exp - ray_oris_exp) * inv_dirs  # [R, B, 3]\n",
    "        t2 = (max_corners_exp - ray_oris_exp) * inv_dirs  # [R, B, 3]\n",
    "        \n",
    "        # Get entry and exit t values for each axis\n",
    "        t_min = to.minimum(t1, t2)                        # [R, B, 3]\n",
    "        t_max = to.maximum(t1, t2)                        # [R, B, 3]\n",
    "        \n",
    "        # Calculate overall entry and exit times\n",
    "        t_entry = to.max(t_min, dim=2)[0]                 # [R, B]\n",
    "        t_exit = to.min(t_max, dim=2)[0]                  # [R, B]\n",
    "        \n",
    "        # A hit occurs when t_exit > max(0, t_entry)\n",
    "        hit = (t_exit > t_entry) & (t_exit > 0)           # [R, B]\n",
    "        \n",
    "        # Use t_entry if positive, otherwise t_exit\n",
    "        t_hit = to.where(t_entry > 0, t_entry, t_exit)    # [R, B]\n",
    "        \n",
    "        # Mark non-hit boxes with infinite distance\n",
    "        t_hit = to.where(hit, t_hit, to.full_like(t_hit, float('inf')))\n",
    "        \n",
    "        # Get top 16 closest hit boxes (or fewer if there aren't 16 hits)\n",
    "        k = min(16, num_boxes)\n",
    "        top_values, top_indices = to.topk(t_hit, k=k, dim=1, largest=False)\n",
    "        \n",
    "        # If fewer than 16 boxes, pad with -1\n",
    "        if k < 16:\n",
    "            padding = to.full((num_rays, 16-k), -1, device=top_indices.device,\n",
    "                            dtype=top_indices.dtype)\n",
    "            top_indices = to.cat([top_indices, padding], dim=1)\n",
    "        \n",
    "        return top_indices\n",
    "    def harmonic_loss(self):\n",
    "        # Compute the current projection of t-values.\n",
    "        blended_t_vals = self.project()\n",
    "    \n",
    "        if to.isnan(blended_t_vals).any() or to.isinf(blended_t_vals).any():\n",
    "            raise ValueError(\"NaN or Inf detected in blended_t_vals\")\n",
    "\n",
    "        # Define hyperparameters.\n",
    "        feature_factor = 0.03\n",
    "        # Compute feature loss using the Laplacian quadratic form.\n",
    "        feature_loss = feature_factor * (\n",
    "            blended_t_vals.T @ self.laplacian @ blended_t_vals\n",
    "        )\n",
    "        \n",
    "        '''\n",
    "        # Set up and solve the implicit update: (I + dt*dampening_factor*L) * f_new = f_prev.\n",
    "        I = to.eye(self.laplacian.shape[0], device=self.laplacian.device)\n",
    "        A = I + dt * dampening_factor * self.laplacian\n",
    "        f_new = to.linalg.solve(A, self.f_prev)\n",
    "\n",
    "        # Compute the implicit loss as the squared difference between the projection and the implicit update.\n",
    "        implicit_loss = to.sum((blended_t_vals - f_new) ** 2)\n",
    "\n",
    "        # Update f_prev for the next iteration without detaching f_new.\n",
    "        self.f_prev = f_new.detach()\n",
    "        '''\n",
    "        # Return the total loss combining implicit and feature losses.\n",
    "        return feature_loss\n",
    "\n",
    "\n",
    "class RenderContext:\n",
    "    def __init__(self, point_size=5, fov=45, distance=10):\n",
    "        # Create a Vispy canvas with an interactive background.\n",
    "        self.canvas = scene.SceneCanvas(\n",
    "            keys=\"interactive\", show=True, bgcolor=\"black\")\n",
    "        self.view = self.canvas.central_widget.add_view()\n",
    "        # Use a TurntableCamera for 3D interaction.\n",
    "        self.view.camera = scene.cameras.TurntableCamera(\n",
    "            fov=fov, distance=distance)\n",
    "        # Create a scatter visual to display points.\n",
    "        self.scatter = scene.visuals.Markers(parent=self.view.scene)\n",
    "        # Initialize with an empty dataset.\n",
    "        self.scatter.set_data(\n",
    "            np.empty((0, 3)), edge_color=None, face_color=(1, 1, 1, 1), size=point_size\n",
    "        )\n",
    "        self.point_size = point_size\n",
    "\n",
    "    def update(self, positions, blended_tvals):\n",
    "        \"\"\"\n",
    "        Update the scatter plot with new 3D positions and color them based on blended_tvals.\n",
    "\n",
    "        Parameters:\n",
    "            positions (np.ndarray): An (N, 3) array of 3D coordinates.\n",
    "            blended_tvals (np.ndarray): A length-N array of scalar values for color mapping.\n",
    "        \"\"\"\n",
    "        if positions is None or positions.size == 0:\n",
    "            return\n",
    "\n",
    "        # Ensure positions is of shape (N, 3)\n",
    "        if positions.ndim != 2 or positions.shape[1] != 3:\n",
    "            raise ValueError(\"positions must be a numpy array of shape (N, 3)\")\n",
    "\n",
    "        # Map blended_tvals to colors if provided.\n",
    "        if blended_tvals is not None and len(blended_tvals) == positions.shape[0]:\n",
    "            min_val = np.min(blended_tvals)\n",
    "            max_val = np.max(blended_tvals)\n",
    "            range_val = max_val - min_val if max_val != min_val else 1.0\n",
    "            normalized = (blended_tvals - min_val) / range_val\n",
    "\n",
    "            # Simple blue-to-red colormap:\n",
    "            colors = np.empty((positions.shape[0], 4), dtype=np.float32)\n",
    "            colors[:, 0] = normalized[:, 0]  # Red increases with value.\n",
    "            colors[:, 1] = 0.2  # Fixed green for consistency.\n",
    "            # Blue decreases with value.\n",
    "            colors[:, 2] = 1 - normalized[:, 0]\n",
    "            colors[:, 3] = 1.0  # Fully opaque.\n",
    "        else:\n",
    "            # Default to white if no valid scalar values are provided.\n",
    "            colors = np.tile(\n",
    "                np.array([1, 1, 1, 1], dtype=np.float32), (positions.shape[0], 1)\n",
    "            )\n",
    "\n",
    "        # Update scatter plot data.\n",
    "        self.scatter.set_data(\n",
    "            positions, face_color=colors, size=self.point_size)\n",
    "        self.canvas.update()\n",
    "        # Process pending GUI events to refresh the display immediately.\n",
    "        app.process_events()\n",
    "\n",
    "\n",
    "def matrix_to_quaternion(rotation_matrices):\n",
    "    N = rotation_matrices.shape[0]\n",
    "    q = to.zeros((N, 4), device=rotation_matrices.device)\n",
    "\n",
    "    trace = to.einsum(\"nii->n\", rotation_matrices)\n",
    "\n",
    "    cond1 = trace > 0\n",
    "    cond2 = (rotation_matrices[:, 0, 0] > rotation_matrices[:, 1, 1]) & ~cond1\n",
    "    cond3 = (rotation_matrices[:, 1, 1] >\n",
    "             rotation_matrices[:, 2, 2]) & ~(cond1 | cond2)\n",
    "    cond4 = ~(cond1 | cond2 | cond3)\n",
    "\n",
    "    S = to.zeros_like(trace)\n",
    "    S[cond1] = to.sqrt(trace[cond1] + 1.0) * 2\n",
    "    q[cond1, 0] = 0.25 * S[cond1]\n",
    "    q[cond1, 1] = (rotation_matrices[cond1, 2, 1] - rotation_matrices[cond1, 1, 2]) / S[\n",
    "        cond1\n",
    "    ]\n",
    "    q[cond1, 2] = (rotation_matrices[cond1, 0, 2] - rotation_matrices[cond1, 2, 0]) / S[\n",
    "        cond1\n",
    "    ]\n",
    "    q[cond1, 3] = (rotation_matrices[cond1, 1, 0] - rotation_matrices[cond1, 0, 1]) / S[\n",
    "        cond1\n",
    "    ]\n",
    "\n",
    "    S[cond2] = (\n",
    "        to.sqrt(\n",
    "            1.0\n",
    "            + rotation_matrices[cond2, 0, 0]\n",
    "            - rotation_matrices[cond2, 1, 1]\n",
    "            - rotation_matrices[cond2, 2, 2]\n",
    "        )\n",
    "        * 2\n",
    "    )\n",
    "    q[cond2, 0] = (rotation_matrices[cond2, 2, 1] - rotation_matrices[cond2, 1, 2]) / S[\n",
    "        cond2\n",
    "    ]\n",
    "    q[cond2, 1] = 0.25 * S[cond2]\n",
    "    q[cond2, 2] = (rotation_matrices[cond2, 0, 1] + rotation_matrices[cond2, 1, 0]) / S[\n",
    "        cond2\n",
    "    ]\n",
    "    q[cond2, 3] = (rotation_matrices[cond2, 0, 2] + rotation_matrices[cond2, 2, 0]) / S[\n",
    "        cond2\n",
    "    ]\n",
    "\n",
    "    S[cond3] = (\n",
    "        to.sqrt(\n",
    "            1.0\n",
    "            + rotation_matrices[cond3, 1, 1]\n",
    "            - rotation_matrices[cond3, 0, 0]\n",
    "            - rotation_matrices[cond3, 2, 2]\n",
    "        )\n",
    "        * 2\n",
    "    )\n",
    "    q[cond3, 0] = (rotation_matrices[cond3, 0, 2] - rotation_matrices[cond3, 2, 0]) / S[\n",
    "        cond3\n",
    "    ]\n",
    "    q[cond3, 1] = (rotation_matrices[cond3, 0, 1] + rotation_matrices[cond3, 1, 0]) / S[\n",
    "        cond3\n",
    "    ]\n",
    "    q[cond3, 2] = 0.25 * S[cond3]\n",
    "    q[cond3, 3] = (rotation_matrices[cond3, 1, 2] + rotation_matrices[cond3, 2, 1]) / S[\n",
    "        cond3\n",
    "    ]\n",
    "\n",
    "    S[cond4] = (\n",
    "        to.sqrt(\n",
    "            1.0\n",
    "            + rotation_matrices[cond4, 2, 2]\n",
    "            - rotation_matrices[cond4, 0, 0]\n",
    "            - rotation_matrices[cond4, 1, 1]\n",
    "        )\n",
    "        * 2\n",
    "    )\n",
    "    q[cond4, 0] = (rotation_matrices[cond4, 1, 0] - rotation_matrices[cond4, 0, 1]) / S[\n",
    "        cond4\n",
    "    ]\n",
    "    q[cond4, 1] = (rotation_matrices[cond4, 0, 2] + rotation_matrices[cond4, 2, 0]) / S[\n",
    "        cond4\n",
    "    ]\n",
    "    q[cond4, 2] = (rotation_matrices[cond4, 1, 2] + rotation_matrices[cond4, 2, 1]) / S[\n",
    "        cond4\n",
    "    ]\n",
    "    q[cond4, 3] = 0.25 * S[cond4]\n",
    "\n",
    "    return q\n",
    "\n",
    "\n",
    "def rot_matrix_to_quaternions(R):\n",
    "    R = R[0, ...]\n",
    "    \"\"\"\n",
    "    Convert an (n,3,3) batch of rotation matrices to (n,4) batch of quaternions.\n",
    "    Args:\n",
    "        R: to.Tensor of shape (n,3,3), where each (3,3) matrix is a rotation matrix.\n",
    "\n",
    "    Returns:\n",
    "        to.Tensor of shape (n,4), where each quaternion is (w, x, y, z).\n",
    "    \"\"\"\n",
    "    n = R.shape[0]\n",
    "\n",
    "    trace = R[:, 0, 0] + R[:, 1, 1] + R[:, 2, 2]\n",
    "\n",
    "    q = to.zeros((n, 4), device=R.device)\n",
    "\n",
    "    # Case w is largest\n",
    "    w_large = trace > 0\n",
    "    if w_large.any():\n",
    "        S = to.sqrt(trace[w_large] + 1.0) * 2  # S=4w\n",
    "        q[w_large, 0] = 0.25 * S\n",
    "        q[w_large, 1] = (R[w_large, 2, 1] - R[w_large, 1, 2]) / S\n",
    "        q[w_large, 2] = (R[w_large, 0, 2] - R[w_large, 2, 0]) / S\n",
    "        q[w_large, 3] = (R[w_large, 1, 0] - R[w_large, 0, 1]) / S\n",
    "\n",
    "    # Case x is largest\n",
    "    x_large = (~w_large) & (R[:, 0, 0] > R[:, 1, 1]) & (\n",
    "        R[:, 0, 0] > R[:, 2, 2])\n",
    "    if x_large.any():\n",
    "        S = to.sqrt(1.0 + R[x_large, 0, 0] -\n",
    "                    R[x_large, 1, 1] - R[x_large, 2, 2]) * 2\n",
    "        q[x_large, 0] = (R[x_large, 2, 1] - R[x_large, 1, 2]) / S\n",
    "        q[x_large, 1] = 0.25 * S\n",
    "        q[x_large, 2] = (R[x_large, 0, 1] + R[x_large, 1, 0]) / S\n",
    "        q[x_large, 3] = (R[x_large, 0, 2] + R[x_large, 2, 0]) / S\n",
    "\n",
    "    # Case y is largest\n",
    "    y_large = (~w_large) & (~x_large) & (R[:, 1, 1] > R[:, 2, 2])\n",
    "    if y_large.any():\n",
    "        S = to.sqrt(1.0 + R[y_large, 1, 1] -\n",
    "                    R[y_large, 0, 0] - R[y_large, 2, 2]) * 2\n",
    "        q[y_large, 0] = (R[y_large, 0, 2] - R[y_large, 2, 0]) / S\n",
    "        q[y_large, 1] = (R[y_large, 0, 1] + R[y_large, 1, 0]) / S\n",
    "        q[y_large, 2] = 0.25 * S\n",
    "        q[y_large, 3] = (R[y_large, 1, 2] + R[y_large, 2, 1]) / S\n",
    "\n",
    "    # Case z is largest\n",
    "    z_large = ~(w_large | x_large | y_large)\n",
    "    if z_large.any():\n",
    "        S = to.sqrt(1.0 + R[z_large, 2, 2] -\n",
    "                    R[z_large, 0, 0] - R[z_large, 1, 1]) * 2\n",
    "        q[z_large, 0] = (R[z_large, 1, 0] - R[z_large, 0, 1]) / S\n",
    "        q[z_large, 1] = (R[z_large, 0, 2] + R[z_large, 2, 0]) / S\n",
    "        q[z_large, 2] = (R[z_large, 1, 2] + R[z_large, 2, 1]) / S\n",
    "        q[z_large, 3] = 0.25 * S\n",
    "\n",
    "    return q\n",
    "\n",
    "\n",
    "def save_optimized_gaussian_model(model, output_path=\"optimized_point_cloud.ply\"):\n",
    "    \"\"\"\n",
    "    Save the optimized Gaussian model to a new PLY file.\n",
    "    The saved file will have all columns identical to the original file,\n",
    "    except that the 'x', 'y', and 'z' columns (means) are updated with the\n",
    "    final optimized values and the quaternion columns ('rot_0', 'rot_1',\n",
    "    'rot_2', 'rot_3') are recomputed from the optimized normals.\n",
    "    \"\"\"\n",
    "    # Re-read the original PLY file to preserve all columns and order.\n",
    "    original_ply = PlyData.read(model.gaussian_model.path)\n",
    "    original_data = original_ply[\"vertex\"].data\n",
    "    df = pd.DataFrame(original_data)\n",
    "\n",
    "    # Update mean coordinates (x, y, z) with optimized values.\n",
    "    new_means = model.means.detach().cpu().numpy()  # shape (N, 3)\n",
    "    df[\"x\"] = new_means[:, 0]\n",
    "    df[\"y\"] = new_means[:, 1]\n",
    "    df[\"z\"] = new_means[:, 2]\n",
    "\n",
    "    # Get rotation matrix that transforms old normals to new normals.\n",
    "    diff_rot = normals_to_rot_matrix(\n",
    "        model.gaussian_model.reference_normals[None, ...], model.normals[None, ...]\n",
    "    ).squeeze(0)\n",
    "    # Convert the diff rot int a diff quat\n",
    "    diff_quats = matrix_to_quaternion(diff_rot)\n",
    "    # Apply the diff quats to new quaternioons\n",
    "    new_quats = (\n",
    "        quaternion_multiply(diff_quats, model.gaussian_model.quaternions)\n",
    "        .detach()\n",
    "        .cpu()\n",
    "        .numpy()\n",
    "    )\n",
    "    df[\"rot_0\"] = new_quats[:, 0]\n",
    "    df[\"rot_1\"] = new_quats[:, 1]\n",
    "    df[\"rot_2\"] = new_quats[:, 2]\n",
    "    df[\"rot_3\"] = new_quats[:, 3]\n",
    "    # Convert the DataFrame back into a structured numpy array with the original dtype.\n",
    "    new_data = df.to_records(index=False)\n",
    "    # Create a PlyElement and write out a binary little-endian PLY file.\n",
    "    ply_element = PlyElement.describe(new_data, \"vertex\")\n",
    "    PlyData([ply_element], text=False).write(output_path)\n",
    "\n",
    "import threading\n",
    "def visualize_depth_updates(model, update_interval=0.1):\n",
    "    \"\"\"\n",
    "    Visualize the current depth values by plotting the points\n",
    "    computed as: ray_ori + (depth * ray_dir)\n",
    "    using Vispy. This function updates every 'update_interval'\n",
    "    seconds.\n",
    "    \"\"\"\n",
    "    from vispy import scene, app\n",
    "    import numpy as np\n",
    "    import torch as to\n",
    "\n",
    "    # Set up the canvas and view.\n",
    "    canvas = scene.SceneCanvas(keys=\"interactive\", bgcolor=\"black\")\n",
    "    view = canvas.central_widget.add_view()\n",
    "    \n",
    "    # Create a markers visual for the projected points.\n",
    "    scatter = scene.visuals.Markers(parent=view.scene)\n",
    "    # Initialize with the ray origins to avoid None data.\n",
    "    initial_points = model.ray_oris.detach().cpu().numpy() + model.f_prev.detach().cpu().numpy() * model.ray_dirs.detach().cpu().numpy()\n",
    "    scatter.set_data(initial_points, face_color='red', size=8)\n",
    "\n",
    "    # Update function called every timer tick.\n",
    "    def update(event):\n",
    "        # Compute new positions as: ray_ori + (depth * ray_dir)     \n",
    "        new_points = model.ray_oris.detach().cpu().numpy() + model.f_prev.detach().cpu().numpy() * model.ray_dirs.detach().cpu().numpy()\n",
    "        # Update scatter data.\n",
    "        scatter.set_data(new_points, face_color='red', size=8)\n",
    "        canvas.update()\n",
    "\n",
    "    # Set up a timer to update the visualization periodically.\n",
    "    timer = app.Timer(interval=update_interval, connect=update, start=True)\n",
    "\n",
    "    view.camera = scene.cameras.TurntableCamera()\n",
    "    view.camera.set_range()\n",
    "    \n",
    "    canvas.show()\n",
    " \n",
    "   \n",
    "def start_visualization(model, update_interval=0.1):\n",
    "    visualize_depth_updates(model, update_interval=update_interval)\n",
    "\n",
    "def train_model(model, num_iterations=100, lr=0.00001):\n",
    "    optimizer = to.optim.Adam(model.parameters(), lr=lr)\n",
    "    model.f_prev = model.project().detach()\n",
    "    vis_thread = threading.Thread(target=start_visualization, args=(model,))\n",
    "    vis_thread.start()\n",
    "    losses = []\n",
    "    for iteration in tqdm(range(num_iterations)):\n",
    "        optimizer.zero_grad()\n",
    "        loss = model.harmonic_loss()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        model.f_prev = model.project().detach()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    plt.plot(to.tensor(losses).detach().cpu())\n",
    "    plt.show()\n",
    "    save_optimized_gaussian_model(\n",
    "        model, output_path=\"optimized_point_cloud.ply\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model = GaussianParameters(\"point_cloud.ply\")\n",
    "    train_model(model=model, num_iterations=1000)\n",
    "    # Get spatial grid parameters\n",
    "    # Call optimized projection function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6efeb23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
